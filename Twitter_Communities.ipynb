{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social Media Analytics Project 8 - Community Detection in a Twitter Network\n",
    "===\n",
    "Goloviatinski Sergiy, Herbelin Ludovic <br />\n",
    "MCS 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "from math import sqrt, log\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COMBINED_PATH = './data/twitter_combined.txt'\n",
    "DATA_OTHERS = './data/twitter/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key: node_id, value: set of social circle ids\n",
    "social_circles={}\n",
    "i=0\n",
    "for filename in os.listdir(DATA_OTHERS):\n",
    "    if filename.split('.')[-1]=='circles':\n",
    "        ego_node=filename.split('.')[0]\n",
    "        social_circles[ego_node]=set()\n",
    "        with open(f'{DATA_OTHERS}/{filename}') as file:\n",
    "\n",
    "            data = file.read()\n",
    "            for line in data.split('\\n'):\n",
    "                nodes=line.split()[1:]\n",
    "                for node in nodes:\n",
    "                    try:\n",
    "                        social_circles[node].add(i)\n",
    "                    except KeyError:\n",
    "                        social_circles[node]=set()\n",
    "                        social_circles[node].add(i)\n",
    "                social_circles[ego_node].add(i)\n",
    "                i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes : 23391\n",
      "Number of edges : 456557\n"
     ]
    }
   ],
   "source": [
    "original_G = nx.Graph()\n",
    "\n",
    "edges = nx.read_edgelist(DATA_COMBINED_PATH)\n",
    "\n",
    "original_G.add_edges_from(edges.edges())\n",
    "\n",
    "for node in list(original_G.nodes):\n",
    "    if node not in social_circles.keys():\n",
    "        original_G.remove_node(node)\n",
    "\n",
    "print(f\"Number of nodes : {len(original_G.nodes)}\")\n",
    "print(f\"Number of edges : {len(original_G.edges())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the size of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(G,n):\n",
    "    \n",
    "    node=random.choice(list(social_circles.keys()))\n",
    "    \n",
    "    visited = set()\n",
    "    visited.add(node)\n",
    "    \n",
    "    while len(visited)<n:\n",
    "        node=random.choice(list(G.neighbors(node)))\n",
    "        visited.add(node)\n",
    "    \n",
    "    visited=list(visited)\n",
    "    \n",
    "    # we copy the graph because some attributes are shared with the original graph after calling subgraph method\n",
    "    G=G.copy()\n",
    "    return G.subgraph(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes : 20\n",
      "Number of edges : 35\n"
     ]
    }
   ],
   "source": [
    "# Reduce the graph size, with random walk\n",
    "N_NODES = 20\n",
    "\n",
    "G = random_walk(original_G,N_NODES)\n",
    "\n",
    "print(f\"Number of nodes : {len(G.nodes)}\")\n",
    "print(f\"Number of edges : {len(G.edges())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Girvan-Newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gn(G, n_iter):\n",
    "    G=G.copy()\n",
    "    \n",
    "    n_communities=0\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        while n_communities<=i+1:\n",
    "            betweennesses=nx.edge_betweenness_centrality(G,normalized=False)\n",
    "\n",
    "            edge_to_remove = max(betweennesses, key=betweennesses.get)\n",
    "            G.remove_edge(edge_to_remove[0],edge_to_remove[1])\n",
    "            n_communities=len(list(nx.connected_components(G)))\n",
    "    \n",
    "    communities=list(nx.connected_components(G))\n",
    "    return dict(zip(list(range(len(communities))),communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(vi_neighbors, vj_neighbors):\n",
    "    return len(vi_neighbors.intersection(vj_neighbors)) / sqrt(len(vi_neighbors) * len(vj_neighbors))\n",
    "\n",
    "def compute_cosine_sim(G, selected_nodes):\n",
    "    nodes_similarities = {}\n",
    "    \n",
    "    # TODO : optimize not to compute multiple times the same product maybe triangular matrix\n",
    "    for node in selected_nodes:\n",
    "        vi_neighbors = set(G[node])\n",
    "        for neighbor in vi_neighbors:\n",
    "            vj_neighbors = set(G[neighbor])\n",
    "            sim = cosine_sim(vi_neighbors, vj_neighbors)\n",
    "            nodes_similarities[(node, neighbor)] = sim\n",
    "    \n",
    "    return nodes_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adamic-Adar similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamic_adar_sim(G, vi_neighbors, vj_neighbors):\n",
    "    common_neighbors = vi_neighbors.intersection(vj_neighbors)\n",
    "    \n",
    "    # sum of 1 / log(nb of neighbors for each common neighbor to vi and vj)\n",
    "    return sum([1 / log(len(G[neighbor])) for neighbor in common_neighbors])\n",
    "        \n",
    "\n",
    "def compute_adamic_adar_sim(G, selected_nodes):\n",
    "    nodes_similarities = {}\n",
    "    \n",
    "    # TODO : optimize not to compute multiple times the same product maybe triangular matrix\n",
    "    for node in selected_nodes:\n",
    "        vi_neighbors = set(G[node])\n",
    "        for neighbor in vi_neighbors:\n",
    "            vj_neighbors = set(G[neighbor])\n",
    "            sim = adamic_adar_sim(G, vi_neighbors, vj_neighbors)\n",
    "            nodes_similarities[(node, neighbor)] = sim\n",
    "    \n",
    "    return nodes_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the clusters and evaluate with different values of iteration level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'250340951', '262764726', '182455769', '17654192', '376946114', '270449528', '195475105', '302847930'}, 1: {'94480069', '351092905', '294198566', '254457417', '152065057', '113298003'}, 2: {'15099384', '19636959', '26202686'}, 3: {'22464533'}, 4: {'19479431', '19637934'}}\n"
     ]
    }
   ],
   "source": [
    "iterations=4\n",
    "communities=compute_gn(G,iterations)\n",
    "print(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'250340951', '262764726', '182455769', '17654192', '376946114', '270449528', '195475105', '302847930'}\n",
      "{'94480069', '351092905', '294198566', '254457417', '152065057', '113298003'}\n",
      "{'15099384', '19636959', '26202686'}\n",
      "{'22464533'}\n",
      "{'19479431', '19637934'}\n"
     ]
    }
   ],
   "source": [
    "# to compare with method from networkx\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "\n",
    "comp = girvan_newman(G)\n",
    "\n",
    "for i in range(iterations-1):\n",
    "    next(comp)\n",
    "for com in next(comp):\n",
    "    print(com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the top K users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 nodes with highest degree : {'270449528': 1.0, '182455769': 0.8571428571428571, '302847930': 0.8571428571428571, '17654192': 0.7142857142857143, '195475105': 0.7142857142857143, '94480069': 0.5714285714285714, '294198566': 0.5714285714285714, '376946114': 0.5714285714285714, '250340951': 0.5714285714285714, '254457417': 0.5714285714285714}\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "\n",
    "if k > len(G):\n",
    "    print(f\"Warning : K chosen : {k} is higher than the number of nodes in the graph : {len(G)}\\n\")\n",
    "\n",
    "nodes_degrees = dict(G.degree())\n",
    "# normalize the node degrees using the max node degree\n",
    "max_deg = max(nodes_degrees.values())\n",
    "nodes_degrees = {node:deg /float(max_deg) for node, deg in nodes_degrees.items()}\n",
    "\n",
    "    \n",
    "# sort the node:degree dictionary\n",
    "nodes_degrees= {node: deg for node, deg in sorted(nodes_degrees.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "\n",
    "top_nodes = list(nodes_degrees)[:k]\n",
    "top_nodes_dict = {node:nodes_degrees[node] for node in top_nodes}\n",
    "print(f\"{k} nodes with highest degree : {top_nodes_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most similar nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar nodes using function : cosine are ('270449528', '302847930') with similarity value : 0.772\n",
      "Most similar nodes using function : adamic-adar are ('270449528', '302847930') with similarity value : 3.243\n"
     ]
    }
   ],
   "source": [
    "similarities_tested = {\n",
    "    'cosine':compute_cosine_sim,\n",
    "    'adamic-adar':compute_adamic_adar_sim,\n",
    "}\n",
    "\n",
    "\n",
    "for similarity_label, similarity_func in similarities_tested.items():\n",
    "    top_nodes_sims = similarity_func(G, top_nodes)\n",
    "    most_similar_pair = max(top_nodes_sims, key=top_nodes_sims.get)\n",
    "    \n",
    "    print(f\"Most similar nodes using function : {similarity_label} are {most_similar_pair} with similarity value : {top_nodes_sims[most_similar_pair]:.3f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
