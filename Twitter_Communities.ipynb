{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Social Media Analytics Project 8 - Community Detection in a Twitter Network\n",
    "===\n",
    "Goloviatinski Sergiy, Herbelin Ludovic <br />\n",
    "MCS 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import networkx as nx\n",
    "from math import sqrt, log\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_COMBINED_PATH = 'data/twitter_combined.txt'\n",
    "DATA_OTHERS = 'data/twitter/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes : 81306\n",
      "Number of edges : 1342310\n"
     ]
    }
   ],
   "source": [
    "original_G = nx.Graph()\n",
    "\n",
    "edges = nx.read_edgelist(DATA_COMBINED_PATH)\n",
    "\n",
    "original_G.add_edges_from(edges.edges())\n",
    "\n",
    "print(f\"Number of nodes : {len(original_G.nodes)}\")\n",
    "print(f\"Number of edges : {len(original_G.edges())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducing the size of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk(G,n):\n",
    "    \n",
    "    node=random.choice(list(G.nodes))\n",
    "    \n",
    "    visited = set()\n",
    "    visited.add(node)\n",
    "    \n",
    "    while len(visited)<n:\n",
    "        node=random.choice(list(G.neighbors(node)))\n",
    "        visited.add(node)\n",
    "    \n",
    "    visited=list(visited)\n",
    "    \n",
    "    # we copy the graph because some attributes are shared with the original graph after calling subgraph method\n",
    "    G=G.copy()\n",
    "    return G.subgraph(visited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes : 10\n",
      "Number of edges : 14\n"
     ]
    }
   ],
   "source": [
    "# Reduce the graph size, with random walk\n",
    "N_NODES = 10\n",
    "\n",
    "G = random_walk(original_G,N_NODES)\n",
    "\n",
    "print(f\"Number of nodes : {len(G.nodes)}\")\n",
    "print(f\"Number of edges : {len(G.edges())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Girvan-Newman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gn(G, n_iter):\n",
    "    G=G.copy()\n",
    "    n_nodes=len(G.nodes)\n",
    "    nodes_affected=set()\n",
    "    \n",
    "    for i in range(n_iter):\n",
    "        betweennesses=nx.edge_betweenness_centrality(G,normalized=False)\n",
    "        max_betweenness=max(betweennesses.values())\n",
    "        for edge, betweeness in betweennesses.items():\n",
    "            # to remove n edges that all have the same value which is equals to max\n",
    "            if betweeness == max_betweenness:\n",
    "                G.remove_edge(edge[0],edge[1])\n",
    "                nodes_affected.add(edge[0])\n",
    "                nodes_affected.add(edge[1])\n",
    "        \n",
    "    # hypothesis: each node affected by the edge removal will be the starting point for a community.\n",
    "    # create a dict with community id as key, and set of nodes in this community as value\n",
    "    communities=dict(zip(list(range(len(nodes_affected))),[set([node]) for node in nodes_affected]))\n",
    "    \n",
    "    duplicate_communities=True\n",
    "    \n",
    "    while duplicate_communities:\n",
    "        n_nodes_in_communities=0\n",
    "        # while all the original nodes are not affected to a community\n",
    "        while n_nodes_in_communities<n_nodes:\n",
    "            for _, community in communities.items():\n",
    "                # Random walk to add nodes to communities\n",
    "                node=random.choice(list(community))\n",
    "                try:\n",
    "                    community.add(random.choice(list(G.neighbors(node))))\n",
    "                except IndexError:\n",
    "                    # If a node has no neighbor, it's a community on its own\n",
    "                    pass\n",
    "\n",
    "            n_nodes_in_communities=len(set().union(*list(communities.values())))\n",
    "\n",
    "            \n",
    "        # Idea to elimite duplicate communities: a duplicate community is created if two starting nodes\n",
    "        # (in nodes_affected list) are reachable from one to another, to avoid duplicating communities, we restart\n",
    "        # the whole process after removing one of the two starting nodes which are in the same community\n",
    "        # from the nodes_affected list\n",
    "        duplicate_communities=False\n",
    "        for i in communities.keys():\n",
    "            for j in communities.keys():\n",
    "                # iterate through the \"matrix\" in a triangular way: avoid to compare a community with itself\n",
    "                # and avoid to compare B with A after we already compared A with B\n",
    "                if i>j:\n",
    "                    nodes_affected_size=len(nodes_affected)\n",
    "                    for node in communities[i]:\n",
    "                        if node in communities[j]:\n",
    "                            duplicate_communities=True\n",
    "                            # The goal is to remove a node that appears in 2 communities from the starting nodes\n",
    "                            if len(nodes_affected)<nodes_affected_size:\n",
    "                                break\n",
    "                            try:\n",
    "                                nodes_affected.remove(node)\n",
    "                            except KeyError:\n",
    "                                pass\n",
    "        \n",
    "        if duplicate_communities:\n",
    "            communities=dict(zip(list(range(len(nodes_affected))),[set([node]) for node in nodes_affected]))\n",
    "    \n",
    "    return communities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim(vi_neighbors, vj_neighbors):\n",
    "    return len(vi_neighbors.intersection(vj_neighbors)) / sqrt(len(vi_neighbors) * len(vj_neighbors))\n",
    "\n",
    "def compute_cosine_sim(G, selected_nodes):\n",
    "    nodes_similarities = {}\n",
    "    \n",
    "    # TODO : optimize not to compute multiple times the same product maybe triangular matrix\n",
    "    for node in selected_nodes:\n",
    "        vi_neighbors = set(G[node])\n",
    "        for neighbor in vi_neighbors:\n",
    "            vj_neighbors = set(G[neighbor])\n",
    "            sim = cosine_sim(vi_neighbors, vj_neighbors)\n",
    "            nodes_similarities[(node, neighbor)] = sim\n",
    "    \n",
    "    return nodes_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adamic-Adar similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adamic_adar_sim(G, vi_neighbors, vj_neighbors):\n",
    "    common_neighbors = vi_neighbors.intersection(vj_neighbors)\n",
    "    \n",
    "    # sum of 1 / log(nb of neighbors for each common neighbor to vi and vj)\n",
    "    return sum([1 / log(len(G[neighbor])) for neighbor in common_neighbors])\n",
    "        \n",
    "\n",
    "def compute_adamic_adar_sim(G, selected_nodes):\n",
    "    nodes_similarities = {}\n",
    "    \n",
    "    # TODO : optimize not to compute multiple times the same product maybe triangular matrix\n",
    "    for node in selected_nodes:\n",
    "        vi_neighbors = set(G[node])\n",
    "        for neighbor in vi_neighbors:\n",
    "            vj_neighbors = set(G[neighbor])\n",
    "            sim = adamic_adar_sim(G, vi_neighbors, vj_neighbors)\n",
    "            nodes_similarities[(node, neighbor)] = sim\n",
    "    \n",
    "    return nodes_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the clusters and evaluate with different values of iteration level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'16812787', '21056862', '37367041', '42384760'},\n",
       " 1: {'17738008', '20714235', '250831586'},\n",
       " 2: {'136311777', '16378996', '83724100'}}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterations=2\n",
    "compute_gn(G,iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'21056862', '42384760', '37367041', '16812787'}\n",
      "{'16378996', '83724100', '136311777'}\n",
      "{'20714235', '250831586', '17738008'}\n"
     ]
    }
   ],
   "source": [
    "# to compare with method from networkx\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "\n",
    "comp = girvan_newman(G)\n",
    "\n",
    "for i in range(iterations-1):\n",
    "    next(comp)\n",
    "for com in next(comp):\n",
    "    print(com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the top K users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "top_nodes = list(G.nodes)[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most similar nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar nodes using function : cosine are ('37367041', '16812787') with similarity value : 0.750\n",
      "Most similar nodes using function : adamic-adar are ('37367041', '16812787') with similarity value : 2.542\n"
     ]
    }
   ],
   "source": [
    "similarities_tested = {\n",
    "    'cosine':compute_cosine_sim,\n",
    "    'adamic-adar':compute_adamic_adar_sim,\n",
    "}\n",
    "\n",
    "\n",
    "for similarity_label, similarity_func in similarities_tested.items():\n",
    "    top_nodes_sims = similarity_func(G, top_nodes)\n",
    "    most_similar_pair = max(top_nodes_sims, key=top_nodes_sims.get)\n",
    "    \n",
    "    print(f\"Most similar nodes using function : {similarity_label} are {most_similar_pair} with similarity value : {top_nodes_sims[most_similar_pair]:.3f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
